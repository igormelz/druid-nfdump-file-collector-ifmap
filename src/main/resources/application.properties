# Quarkus
quarkus.log.file.enable = false

# Camel
camel.context.name = druid-nfdump-collector

# collector parameters
## parsed columns for nfdump pipe format 
parser.spec= %skip,first,%skip,last,%skip,proto,%skip,%skip,%skip,srcip,srcport,%skip,%skip,%skip,dstip,dstport,srcas,dstas,in,out,%skip,%skip,%skip,bytes
#parser.delimiter=
## output columns
output.spec= last,customer,vlan,direction,uplink,proto,local_ip,local_port,asn,remote_ip,remote_port,bytes
#output.delimiter=
#output.tmpdir=
#output.header=

## src host and path to nfdump files
#source=
## dest host and path to result file 
#destination=
## baseDir an absolute path to indexing files
#destination.dir=
## ssh-key 
#sshKeyFile=
## exec command
#nfdump.cmd=nfdump
## exec args
#nfdump.args=
## druid url
#ccoordinator.url=http://localhost:8081
## index.json 
# indexJson=

## simple map ifIndex to uplink name 
## format key,value[,key,value]*
# map.uplink.spec = 1001,UPLINK-1,1002,UPLINK-2

## simple map proto to protocol 
map.protocol.spec = 1,icmp,4,ipv4,6,tcp,17,udp,41,ipv6,47,gre,50,esp

# define lookup table for mapping ipaddr to customer
lookup.customer.mapFileUrl= file:config/ip.dat
# pattern format: ipnet\tcustomer\tvlanId\tstatus<eol>
lookup.customer.pattern= (.*)\\t(.*)\\t(.*)\\t(.*)[\\r\\n]*
# key fields: ipnet
lookup.customer.keyColumnIndex= 1
# data fields: customer,vlan
lookup.customer.dataColumnIndex= 2,3
# use message body
lookup.customer.useHeaders= false
# message fields to lookup 
lookup.customer.mapKeys= local_ip
# return field name
lookup.customer.mapValues= customer,vlan
# set default values if not found 
lookup.customer.valueDefaults= NaN,NaN
# 15 min reload
lookup.customer.reloadInterval= 1800
