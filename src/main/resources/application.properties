# Quarkus
quarkus.log.file.enable = false

# Camel
camel.context.name = druid-nfdump-collector
camel.main.messageHistory = false
camel.main.streamCachingEnabled = false
camel.main.threadNamePattern = ##counter# #name#

# collector parameters
parser.spec= %skip,first,%skip,last,%skip,proto,%skip,%skip,%skip,srcip,srcport,%skip,%skip,%skip,dstip,dstport,srcas,dstas,inif,outif,%skip,%skip,%skip,bytes
#parser.delimiter=\\|
output.spec= last,customer,vlan,direction,uplink,proto,local_ip,local_port,asn,remote_ip,remote_port,bytes
#output.delimiter= ;
#output.tmpdir= /tmp/output
#output.header= true

## src host and path to nfdump files
source=user@remote:/in
## dest host and path to result file 
destination=user@druid:/nfdump
## baseDir an absolute path to indexing files
destination.dir=/var/nfdump
## ssh-key 
sshKeyFile=id_pub.rsa
## exec command
nfdump.cmd=nfdump
## exec args
nfdump.args=args
## druid url
coordinator.url=http://localhost:8081
## index.json 
indexJson=resource:classpath:index.json

## simple map ifIndex to uplink name as key,value[,key,value]*
map.uplink.spec = 100,UPLINK100,200,UPLINK200

## simple map proto to protocol
map.protocol.spec = 1,icmp,4,ipv4,6,tcp,17,udp,41,ipv6,47,gre,50,esp

# define lookup table for mapping ipaddr to customer
lookup.customer.mapFileUrl= file:ip2customer.dat
# pattern format: subnet\tcustomer\tvlan\tstatus<eol>
lookup.customer.pattern= (.*)\\t(.*)\\t(.*)\\t(.*)[\\r\\n]*
# key fields: subnet
lookup.customer.keyColumnIndex= 1
# data fields: customer,vlan
lookup.customer.dataColumnIndex= 2,3
# use message body or headers
lookup.customer.useHeaders= false
# message fields to lookup 
lookup.customer.mapKeys= ipaddr
# return field name
lookup.customer.mapValues= customer,vlan
# set default values if not found 
lookup.customer.valueDefaults= NaN,NaN
# 15 min reload
lookup.customer.reloadInterval= 1800
