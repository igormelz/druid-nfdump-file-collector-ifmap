# Quarkus
quarkus.log.file.enable = false

# Camel
camel.context.name = druid-nfdump-collector

# collector parameters
## parsed columns for nfdump pipe format 
parser.spec= %skip,first,%skip,last,%skip,proto,%skip,%skip,%skip,srcip,srcport,%skip,%skip,%skip,dstip,dstport,srcas,dstas,inif,outif,%skip,%skip,%skip,bytes
#parser.delimiter=
## output columns
output.spec= last,customer,vlan,direction,uplink,proto,local_ip,local_port,asn,remote_ip,remote_port,bytes,ref
#output.delimiter=
#output.tmpdir=
#output.header=

## src host and path to nfdump files
source=source
## dest host and path to result file 
destination=dest
## baseDir an absolute path to indexing files
destination.dir=dir
## ssh-key 
sshKeyFile=ssh
## exec command
nfdump.cmd=nfdump
## exec args
nfdump.args=args
## druid url
coordinator.url=http://localhost:8081
## index.json 
indexJson=resource:classpath:index.json

## simple map ifIndex to uplink name 
## format key,value[,key,value]*
map.uplink.spec = 562,CLOUD-IX,571,RETN,691,ROSTEL,690,BEELINE,689,RUNNET,688,RETN

## simple map proto to protocol
map.protocol.spec = 1,icmp,4,ipv4,6,tcp,17,udp,41,ipv6,47,gre,50,esp

# define lookup table for mapping ipaddr to customer
lookup.customer.mapFileUrl= file:ip.dat
# pattern format: ipnet\tcustomer\tvlanId\tstatus<eol>
lookup.customer.pattern= (.*)\\t(.*)\\t(.*)\\t(.*)[\\r\\n]*
# key fields: ipnet
lookup.customer.keyColumnIndex= 1
# data fields: customer,vlan
lookup.customer.dataColumnIndex= 2,3
# use message body
lookup.customer.useHeaders= false
# message fields to lookup 
lookup.customer.mapKeys= ipaddr
# return field name
lookup.customer.mapValues= customer,vlan
# set default values if not found 
lookup.customer.valueDefaults= NaN,NaN
# 15 min reload
lookup.customer.reloadInterval= 1800
